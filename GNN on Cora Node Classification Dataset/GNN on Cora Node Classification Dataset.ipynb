{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9LETUsXWoGb"
      },
      "source": [
        "# Graph Neural Networks with Deep Graph Library\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7TTB9rMWoGd"
      },
      "source": [
        "## Creating a DGL graph from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbNo-4jmML1h",
        "outputId": "4464ee99-556f-4c11-efb1-532194941281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels/cu116/repo.html\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.8/dist-packages (1.0.1+cu116)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.25.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (3.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Requirement already satisfied: dglgo in /usr/local/lib/python3.8/dist-packages (0.0.2)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.20 in /usr/local/lib/python3.8/dist-packages (from dglgo) (0.17.21)\n",
            "Requirement already satisfied: autopep8>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (2.0.2)\n",
            "Requirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (1.10.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (1.2.1)\n",
            "Requirement already satisfied: numpydoc>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (1.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from dglgo) (6.0)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.8/dist-packages (from dglgo) (2022.9.5)\n",
            "Requirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from dglgo) (0.7.0)\n",
            "Requirement already satisfied: ogb>=1.3.3 in /usr/local/lib/python3.8/dist-packages (from dglgo) (1.3.5)\n",
            "Requirement already satisfied: isort>=5.10.1 in /usr/local/lib/python3.8/dist-packages (from dglgo) (6.0.0b2)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.8/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from autopep8>=1.6.0->dglgo) (2.10.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.8/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: sphinx>=4.2 in /usr/local/lib/python3.8/dist-packages (from numpydoc>=1.1.0->dglgo) (6.1.3)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (4.64.1)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.26.14)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.3.5)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.13.1+cu116)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from ogb>=1.3.3->dglgo) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.8/dist-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.7)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.25.1)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.8/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (0.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: docutils<0.20,>=0.18 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.19)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (6.0.0)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8->sphinx>=4.2->numpydoc>=1.1.0->dglgo) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre dgl -f https://data.dgl.ai/wheels/cu116/repo.html\n",
        "!pip install --pre dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17-mItiyWoGf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUt2SgWSWoGg",
        "outputId": "9a790c45-2099-48a8-b6a6-a94f1c1f4811"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graph(num_nodes=10, num_edges=7,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "U = [0, 1, 2, 4, 5, 6, 9]\n",
        "V = [1, 9, 4, 0, 0, 1, 2]\n",
        "G = dgl.graph((U, V)) # directed by default\n",
        "G # nodes 3, 7, 8 are automatically constructed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wuzf2tboXbY"
      },
      "source": [
        "You can create your graphs manually similar to above or you can use external sources (visit the [dgl documentation](https://docs.dgl.ai/guide/graph-external.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTZkCVxlWoGh"
      },
      "source": [
        "Graphs functions somewhat like a dictionary. You could add some information to the edges and the nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFAaZAfkWoGi",
        "outputId": "bdf8b397-72f5-4b89-8d0a-d07287acaa15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graph(num_nodes=10, num_edges=7,\n",
              "      ndata_schemes={'features': Scheme(shape=(10,), dtype=torch.float32), 'labels': Scheme(shape=(1,), dtype=torch.int64)}\n",
              "      edata_schemes={})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.ndata['features'] = torch.eye(10)\n",
        "G.ndata['labels'] = torch.randint(3,size=(10,1))\n",
        "G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34PFkuZQWoGj"
      },
      "source": [
        "To access the features of node 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hrc4TPHWoGk",
        "outputId": "95d6e551-ab45-4e0b-cd5c-bc535dadfa57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.ndata['features'][5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8nrCWBhWoGl"
      },
      "source": [
        "Placing graph in your GPU is similar to a placing a tensor.\n",
        "\n",
        "Note: the node information are also placed in the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwEXcaTAWoGm",
        "outputId": "d40212af-dedf-4af6-f028-f1749f2fa8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n",
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(G.device)\n",
        "print(G.ndata['features'].device)\n",
        "G = G.to('cuda') # G.cuda()\n",
        "print(G.device)\n",
        "print(G.ndata['features'].device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysW4JnU0WoGm"
      },
      "source": [
        "## Using Graph Convolutional Networks\n",
        "\n",
        "We used the Cora node classification dataset. Each node is a scientific publication and edges mean citations. Each publication is classified into one of the 7 subjects: ``Case_Based``,``Genetic_Algorithms``, ``Neural_Networks``, ``Probabilistic_Methods``, ``Reinforcement_Learning``, ``Rule_Learning``, ``Theory``. The node features represent the existence of a specific word in the paper (only 1433 words) with some normalization.\n",
        "\n",
        "Given this citation network and the node features, we want to classify the subject of the nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Tl36iZWoGn",
        "outputId": "66ec6734-8b4d-4173-e577-b002be4dc466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ],
      "source": [
        "from dgl.data import CoraGraphDataset\n",
        "dataset = CoraGraphDataset()\n",
        "G = dataset[0] # this is a Dataset with only one graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02bN177MWoGn",
        "outputId": "fde78d58-c922-4597-bb39-d8a17708374f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graph(num_nodes=2708, num_edges=10556,\n",
              "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
              "      edata_schemes={})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_gE9MfHWoGo",
        "outputId": "16abcda7-2db2-4235-9802-5248f43f110b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.ndata['feat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbjIbfzOUg8n",
        "outputId": "9d86d5bc-f6f1-4aa3-e762-6f9f7386aac6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.1111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.1111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.ndata['feat'][0, :100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrqu0gPWoGo",
        "outputId": "5a3ea509-f6c1-44fe-db55-084838a2542b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 4, 4,  ..., 3, 3, 3])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.ndata['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRSLfTsAU5eo",
        "outputId": "0eb0b799-d504-441f-d74e-fcb03eee33f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True,  ..., False, False, False])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.ndata['train_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce9H-qfWWoGp",
        "outputId": "f2a91e98-4705-491e-ba15-9fa14d704515"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
              "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
              "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
              "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
              "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
              "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
              "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
              "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
              "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.arange(G.number_of_nodes())[G.ndata['train_mask']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYu2MHnJpK7D",
        "outputId": "99d751ec-835f-44ae-9e41-52bc2c5d9f5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
              "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
              "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
              "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
              "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
              "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
              "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
              "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
              "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
              "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
              "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
              "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
              "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
              "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
              "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
              "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
              "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
              "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
              "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
              "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
              "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
              "        504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
              "        518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
              "        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
              "        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
              "        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
              "        574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n",
              "        588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
              "        602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
              "        616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n",
              "        630, 631, 632, 633, 634, 635, 636, 637, 638, 639])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.arange(G.number_of_nodes())[G.ndata['val_mask']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9rss5y8WoGq",
        "outputId": "21b83207-82c6-4cf6-a166-926dcf1ff8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "140\n",
            "500\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "print(len(torch.arange(G.number_of_nodes())[G.ndata['train_mask']]))\n",
        "print(len(torch.arange(G.number_of_nodes())[G.ndata['val_mask']]))\n",
        "print(len(torch.arange(G.number_of_nodes())[G.ndata['test_mask']]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph27Nd7nWoGq"
      },
      "source": [
        "### Defining the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhz4EXv0WoGq"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from dgl.nn import GraphConv # GCN\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_class):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, num_class)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        h = F.elu(self.conv1(g, h))\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtcpZWzCWoGs"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saRV86w7WoGs"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, labels):\n",
        "    _, idx = torch.max(output, dim=1)\n",
        "    correct = torch.sum(idx == labels)\n",
        "    return correct.item()/len(labels)\n",
        "\n",
        "def train_whole(G, model, device, epochs):\n",
        "    g = G.to(device)\n",
        "\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = g.ndata['train_mask']\n",
        "    val_mask = g.ndata['val_mask']\n",
        "    test_mask = g.ndata['test_mask']\n",
        "\n",
        "    # add self loop since we are using GraphConv\n",
        "    g = dgl.remove_self_loop(g) # remove self-loops first because we do not want duplicate edges\n",
        "    g = dgl.add_self_loop(g)\n",
        "    model = model.to(device)\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=5e-4)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(g, features) # what is the size of features? number_of_nodes X num_feats --> nodes X 7\n",
        "        loss = ce_loss(logits[train_mask], labels[train_mask]) # use only training nodes for the loss\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc = accuracy(logits[train_mask], labels[train_mask]) # calculate training accuracy\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model(g, features)\n",
        "            logits = logits[val_mask]\n",
        "            val_lab = labels[val_mask]\n",
        "        val_acc = accuracy(logits, val_lab)\n",
        "\n",
        "        print(\"Epoch {:03d} | Loss {:.4f} | TrainAcc {:.4f} |\"\n",
        "              \" ValAcc {:.4f}\".format(epoch, loss.item(), train_acc, val_acc))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(g, features)\n",
        "        logits = logits[test_mask]\n",
        "        test_lab = labels[test_mask]\n",
        "        acc = accuracy(logits, test_lab)\n",
        "    print(\"Test Accuracy {:.4f}\".format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRAoGRAUWoGs",
        "outputId": "04b84e24-84d1-4570-ae7d-8dde13b93b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | Loss 1.9478 | TrainAcc 0.0857 | ValAcc 0.0720\n",
            "Epoch 002 | Loss 1.9438 | TrainAcc 0.1500 | ValAcc 0.0760\n",
            "Epoch 003 | Loss 1.9400 | TrainAcc 0.1786 | ValAcc 0.0980\n",
            "Epoch 004 | Loss 1.9361 | TrainAcc 0.2214 | ValAcc 0.1380\n",
            "Epoch 005 | Loss 1.9323 | TrainAcc 0.2929 | ValAcc 0.1860\n",
            "Epoch 006 | Loss 1.9284 | TrainAcc 0.4000 | ValAcc 0.2320\n",
            "Epoch 007 | Loss 1.9244 | TrainAcc 0.4714 | ValAcc 0.2800\n",
            "Epoch 008 | Loss 1.9204 | TrainAcc 0.5214 | ValAcc 0.3100\n",
            "Epoch 009 | Loss 1.9163 | TrainAcc 0.5357 | ValAcc 0.3180\n",
            "Epoch 010 | Loss 1.9121 | TrainAcc 0.5500 | ValAcc 0.3280\n",
            "Epoch 011 | Loss 1.9078 | TrainAcc 0.5929 | ValAcc 0.3520\n",
            "Epoch 012 | Loss 1.9035 | TrainAcc 0.6500 | ValAcc 0.3840\n",
            "Epoch 013 | Loss 1.8990 | TrainAcc 0.6714 | ValAcc 0.4120\n",
            "Epoch 014 | Loss 1.8945 | TrainAcc 0.7286 | ValAcc 0.4440\n",
            "Epoch 015 | Loss 1.8898 | TrainAcc 0.7500 | ValAcc 0.4780\n",
            "Epoch 016 | Loss 1.8851 | TrainAcc 0.7429 | ValAcc 0.4940\n",
            "Epoch 017 | Loss 1.8803 | TrainAcc 0.7571 | ValAcc 0.5020\n",
            "Epoch 018 | Loss 1.8754 | TrainAcc 0.7786 | ValAcc 0.5080\n",
            "Epoch 019 | Loss 1.8704 | TrainAcc 0.8000 | ValAcc 0.5220\n",
            "Epoch 020 | Loss 1.8652 | TrainAcc 0.8000 | ValAcc 0.5340\n",
            "Epoch 021 | Loss 1.8600 | TrainAcc 0.8000 | ValAcc 0.5400\n",
            "Epoch 022 | Loss 1.8547 | TrainAcc 0.8286 | ValAcc 0.5460\n",
            "Epoch 023 | Loss 1.8492 | TrainAcc 0.8286 | ValAcc 0.5540\n",
            "Epoch 024 | Loss 1.8437 | TrainAcc 0.8429 | ValAcc 0.5660\n",
            "Epoch 025 | Loss 1.8380 | TrainAcc 0.8571 | ValAcc 0.5700\n",
            "Epoch 026 | Loss 1.8322 | TrainAcc 0.8571 | ValAcc 0.5760\n",
            "Epoch 027 | Loss 1.8263 | TrainAcc 0.8643 | ValAcc 0.5840\n",
            "Epoch 028 | Loss 1.8203 | TrainAcc 0.8714 | ValAcc 0.5860\n",
            "Epoch 029 | Loss 1.8141 | TrainAcc 0.8929 | ValAcc 0.5940\n",
            "Epoch 030 | Loss 1.8079 | TrainAcc 0.8929 | ValAcc 0.5980\n",
            "Epoch 031 | Loss 1.8015 | TrainAcc 0.8929 | ValAcc 0.6000\n",
            "Epoch 032 | Loss 1.7950 | TrainAcc 0.8929 | ValAcc 0.6040\n",
            "Epoch 033 | Loss 1.7885 | TrainAcc 0.8929 | ValAcc 0.6060\n",
            "Epoch 034 | Loss 1.7818 | TrainAcc 0.9000 | ValAcc 0.6080\n",
            "Epoch 035 | Loss 1.7750 | TrainAcc 0.9000 | ValAcc 0.6160\n",
            "Epoch 036 | Loss 1.7680 | TrainAcc 0.9000 | ValAcc 0.6180\n",
            "Epoch 037 | Loss 1.7610 | TrainAcc 0.9000 | ValAcc 0.6280\n",
            "Epoch 038 | Loss 1.7539 | TrainAcc 0.9071 | ValAcc 0.6400\n",
            "Epoch 039 | Loss 1.7466 | TrainAcc 0.9071 | ValAcc 0.6480\n",
            "Epoch 040 | Loss 1.7392 | TrainAcc 0.9071 | ValAcc 0.6520\n",
            "Epoch 041 | Loss 1.7318 | TrainAcc 0.9071 | ValAcc 0.6580\n",
            "Epoch 042 | Loss 1.7242 | TrainAcc 0.9143 | ValAcc 0.6620\n",
            "Epoch 043 | Loss 1.7165 | TrainAcc 0.9214 | ValAcc 0.6680\n",
            "Epoch 044 | Loss 1.7087 | TrainAcc 0.9214 | ValAcc 0.6740\n",
            "Epoch 045 | Loss 1.7007 | TrainAcc 0.9214 | ValAcc 0.6740\n",
            "Epoch 046 | Loss 1.6927 | TrainAcc 0.9214 | ValAcc 0.6820\n",
            "Epoch 047 | Loss 1.6846 | TrainAcc 0.9214 | ValAcc 0.6820\n",
            "Epoch 048 | Loss 1.6764 | TrainAcc 0.9214 | ValAcc 0.6840\n",
            "Epoch 049 | Loss 1.6681 | TrainAcc 0.9214 | ValAcc 0.6880\n",
            "Epoch 050 | Loss 1.6597 | TrainAcc 0.9286 | ValAcc 0.6940\n",
            "Epoch 051 | Loss 1.6512 | TrainAcc 0.9286 | ValAcc 0.6980\n",
            "Epoch 052 | Loss 1.6426 | TrainAcc 0.9286 | ValAcc 0.6980\n",
            "Epoch 053 | Loss 1.6339 | TrainAcc 0.9286 | ValAcc 0.6980\n",
            "Epoch 054 | Loss 1.6252 | TrainAcc 0.9357 | ValAcc 0.7000\n",
            "Epoch 055 | Loss 1.6163 | TrainAcc 0.9357 | ValAcc 0.6980\n",
            "Epoch 056 | Loss 1.6074 | TrainAcc 0.9357 | ValAcc 0.7000\n",
            "Epoch 057 | Loss 1.5984 | TrainAcc 0.9357 | ValAcc 0.7000\n",
            "Epoch 058 | Loss 1.5894 | TrainAcc 0.9357 | ValAcc 0.6980\n",
            "Epoch 059 | Loss 1.5802 | TrainAcc 0.9429 | ValAcc 0.6980\n",
            "Epoch 060 | Loss 1.5710 | TrainAcc 0.9429 | ValAcc 0.6920\n",
            "Epoch 061 | Loss 1.5618 | TrainAcc 0.9357 | ValAcc 0.6940\n",
            "Epoch 062 | Loss 1.5525 | TrainAcc 0.9357 | ValAcc 0.6920\n",
            "Epoch 063 | Loss 1.5431 | TrainAcc 0.9357 | ValAcc 0.6940\n",
            "Epoch 064 | Loss 1.5337 | TrainAcc 0.9357 | ValAcc 0.6920\n",
            "Epoch 065 | Loss 1.5242 | TrainAcc 0.9357 | ValAcc 0.6960\n",
            "Epoch 066 | Loss 1.5147 | TrainAcc 0.9357 | ValAcc 0.6960\n",
            "Epoch 067 | Loss 1.5051 | TrainAcc 0.9357 | ValAcc 0.6940\n",
            "Epoch 068 | Loss 1.4956 | TrainAcc 0.9357 | ValAcc 0.6940\n",
            "Epoch 069 | Loss 1.4859 | TrainAcc 0.9286 | ValAcc 0.6980\n",
            "Epoch 070 | Loss 1.4763 | TrainAcc 0.9286 | ValAcc 0.6980\n",
            "Epoch 071 | Loss 1.4666 | TrainAcc 0.9286 | ValAcc 0.7000\n",
            "Epoch 072 | Loss 1.4569 | TrainAcc 0.9286 | ValAcc 0.7020\n",
            "Epoch 073 | Loss 1.4472 | TrainAcc 0.9286 | ValAcc 0.7060\n",
            "Epoch 074 | Loss 1.4375 | TrainAcc 0.9286 | ValAcc 0.7040\n",
            "Epoch 075 | Loss 1.4278 | TrainAcc 0.9286 | ValAcc 0.7060\n",
            "Epoch 076 | Loss 1.4181 | TrainAcc 0.9286 | ValAcc 0.7060\n",
            "Epoch 077 | Loss 1.4083 | TrainAcc 0.9286 | ValAcc 0.7060\n",
            "Epoch 078 | Loss 1.3986 | TrainAcc 0.9286 | ValAcc 0.7080\n",
            "Epoch 079 | Loss 1.3889 | TrainAcc 0.9286 | ValAcc 0.7100\n",
            "Epoch 080 | Loss 1.3792 | TrainAcc 0.9286 | ValAcc 0.7100\n",
            "Epoch 081 | Loss 1.3695 | TrainAcc 0.9286 | ValAcc 0.7120\n",
            "Epoch 082 | Loss 1.3598 | TrainAcc 0.9286 | ValAcc 0.7100\n",
            "Epoch 083 | Loss 1.3501 | TrainAcc 0.9357 | ValAcc 0.7140\n",
            "Epoch 084 | Loss 1.3405 | TrainAcc 0.9429 | ValAcc 0.7140\n",
            "Epoch 085 | Loss 1.3308 | TrainAcc 0.9429 | ValAcc 0.7140\n",
            "Epoch 086 | Loss 1.3212 | TrainAcc 0.9429 | ValAcc 0.7160\n",
            "Epoch 087 | Loss 1.3117 | TrainAcc 0.9429 | ValAcc 0.7160\n",
            "Epoch 088 | Loss 1.3021 | TrainAcc 0.9429 | ValAcc 0.7140\n",
            "Epoch 089 | Loss 1.2926 | TrainAcc 0.9429 | ValAcc 0.7160\n",
            "Epoch 090 | Loss 1.2832 | TrainAcc 0.9429 | ValAcc 0.7180\n",
            "Epoch 091 | Loss 1.2738 | TrainAcc 0.9429 | ValAcc 0.7200\n",
            "Epoch 092 | Loss 1.2644 | TrainAcc 0.9429 | ValAcc 0.7220\n",
            "Epoch 093 | Loss 1.2551 | TrainAcc 0.9429 | ValAcc 0.7240\n",
            "Epoch 094 | Loss 1.2458 | TrainAcc 0.9429 | ValAcc 0.7280\n",
            "Epoch 095 | Loss 1.2366 | TrainAcc 0.9429 | ValAcc 0.7280\n",
            "Epoch 096 | Loss 1.2274 | TrainAcc 0.9429 | ValAcc 0.7280\n",
            "Epoch 097 | Loss 1.2183 | TrainAcc 0.9500 | ValAcc 0.7300\n",
            "Epoch 098 | Loss 1.2092 | TrainAcc 0.9500 | ValAcc 0.7300\n",
            "Epoch 099 | Loss 1.2002 | TrainAcc 0.9500 | ValAcc 0.7300\n",
            "Epoch 100 | Loss 1.1912 | TrainAcc 0.9429 | ValAcc 0.7300\n",
            "Epoch 101 | Loss 1.1823 | TrainAcc 0.9643 | ValAcc 0.7300\n",
            "Epoch 102 | Loss 1.1735 | TrainAcc 0.9643 | ValAcc 0.7300\n",
            "Epoch 103 | Loss 1.1648 | TrainAcc 0.9643 | ValAcc 0.7320\n",
            "Epoch 104 | Loss 1.1561 | TrainAcc 0.9643 | ValAcc 0.7320\n",
            "Epoch 105 | Loss 1.1474 | TrainAcc 0.9643 | ValAcc 0.7320\n",
            "Epoch 106 | Loss 1.1389 | TrainAcc 0.9643 | ValAcc 0.7320\n",
            "Epoch 107 | Loss 1.1304 | TrainAcc 0.9714 | ValAcc 0.7320\n",
            "Epoch 108 | Loss 1.1220 | TrainAcc 0.9714 | ValAcc 0.7320\n",
            "Epoch 109 | Loss 1.1136 | TrainAcc 0.9714 | ValAcc 0.7300\n",
            "Epoch 110 | Loss 1.1053 | TrainAcc 0.9714 | ValAcc 0.7300\n",
            "Epoch 111 | Loss 1.0971 | TrainAcc 0.9714 | ValAcc 0.7300\n",
            "Epoch 112 | Loss 1.0890 | TrainAcc 0.9714 | ValAcc 0.7300\n",
            "Epoch 113 | Loss 1.0809 | TrainAcc 0.9714 | ValAcc 0.7300\n",
            "Epoch 114 | Loss 1.0729 | TrainAcc 0.9714 | ValAcc 0.7300\n",
            "Epoch 115 | Loss 1.0650 | TrainAcc 0.9714 | ValAcc 0.7300\n",
            "Epoch 116 | Loss 1.0572 | TrainAcc 0.9714 | ValAcc 0.7320\n",
            "Epoch 117 | Loss 1.0494 | TrainAcc 0.9714 | ValAcc 0.7320\n",
            "Epoch 118 | Loss 1.0417 | TrainAcc 0.9714 | ValAcc 0.7320\n",
            "Epoch 119 | Loss 1.0341 | TrainAcc 0.9714 | ValAcc 0.7320\n",
            "Epoch 120 | Loss 1.0265 | TrainAcc 0.9714 | ValAcc 0.7320\n",
            "Epoch 121 | Loss 1.0191 | TrainAcc 0.9714 | ValAcc 0.7340\n",
            "Epoch 122 | Loss 1.0117 | TrainAcc 0.9714 | ValAcc 0.7340\n",
            "Epoch 123 | Loss 1.0044 | TrainAcc 0.9714 | ValAcc 0.7340\n",
            "Epoch 124 | Loss 0.9971 | TrainAcc 0.9714 | ValAcc 0.7380\n",
            "Epoch 125 | Loss 0.9899 | TrainAcc 0.9714 | ValAcc 0.7380\n",
            "Epoch 126 | Loss 0.9829 | TrainAcc 0.9714 | ValAcc 0.7400\n",
            "Epoch 127 | Loss 0.9758 | TrainAcc 0.9714 | ValAcc 0.7420\n",
            "Epoch 128 | Loss 0.9689 | TrainAcc 0.9714 | ValAcc 0.7440\n",
            "Epoch 129 | Loss 0.9620 | TrainAcc 0.9714 | ValAcc 0.7440\n",
            "Epoch 130 | Loss 0.9552 | TrainAcc 0.9714 | ValAcc 0.7460\n",
            "Epoch 131 | Loss 0.9485 | TrainAcc 0.9714 | ValAcc 0.7460\n",
            "Epoch 132 | Loss 0.9418 | TrainAcc 0.9714 | ValAcc 0.7460\n",
            "Epoch 133 | Loss 0.9352 | TrainAcc 0.9714 | ValAcc 0.7460\n",
            "Epoch 134 | Loss 0.9287 | TrainAcc 0.9714 | ValAcc 0.7500\n",
            "Epoch 135 | Loss 0.9223 | TrainAcc 0.9714 | ValAcc 0.7500\n",
            "Epoch 136 | Loss 0.9159 | TrainAcc 0.9714 | ValAcc 0.7500\n",
            "Epoch 137 | Loss 0.9096 | TrainAcc 0.9714 | ValAcc 0.7540\n",
            "Epoch 138 | Loss 0.9033 | TrainAcc 0.9714 | ValAcc 0.7580\n",
            "Epoch 139 | Loss 0.8972 | TrainAcc 0.9714 | ValAcc 0.7580\n",
            "Epoch 140 | Loss 0.8910 | TrainAcc 0.9786 | ValAcc 0.7580\n",
            "Epoch 141 | Loss 0.8850 | TrainAcc 0.9786 | ValAcc 0.7580\n",
            "Epoch 142 | Loss 0.8790 | TrainAcc 0.9786 | ValAcc 0.7580\n",
            "Epoch 143 | Loss 0.8731 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 144 | Loss 0.8673 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 145 | Loss 0.8615 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 146 | Loss 0.8558 | TrainAcc 0.9786 | ValAcc 0.7600\n",
            "Epoch 147 | Loss 0.8501 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 148 | Loss 0.8446 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 149 | Loss 0.8390 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 150 | Loss 0.8335 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 151 | Loss 0.8281 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 152 | Loss 0.8228 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 153 | Loss 0.8175 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 154 | Loss 0.8123 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 155 | Loss 0.8071 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 156 | Loss 0.8020 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 157 | Loss 0.7969 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 158 | Loss 0.7919 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 159 | Loss 0.7869 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 160 | Loss 0.7820 | TrainAcc 0.9786 | ValAcc 0.7580\n",
            "Epoch 161 | Loss 0.7772 | TrainAcc 0.9786 | ValAcc 0.7580\n",
            "Epoch 162 | Loss 0.7724 | TrainAcc 0.9786 | ValAcc 0.7600\n",
            "Epoch 163 | Loss 0.7676 | TrainAcc 0.9786 | ValAcc 0.7600\n",
            "Epoch 164 | Loss 0.7629 | TrainAcc 0.9786 | ValAcc 0.7600\n",
            "Epoch 165 | Loss 0.7583 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 166 | Loss 0.7536 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 167 | Loss 0.7491 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 168 | Loss 0.7446 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 169 | Loss 0.7401 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 170 | Loss 0.7357 | TrainAcc 0.9786 | ValAcc 0.7620\n",
            "Epoch 171 | Loss 0.7314 | TrainAcc 0.9786 | ValAcc 0.7640\n",
            "Epoch 172 | Loss 0.7270 | TrainAcc 0.9786 | ValAcc 0.7640\n",
            "Epoch 173 | Loss 0.7228 | TrainAcc 0.9786 | ValAcc 0.7660\n",
            "Epoch 174 | Loss 0.7185 | TrainAcc 0.9786 | ValAcc 0.7640\n",
            "Epoch 175 | Loss 0.7143 | TrainAcc 0.9786 | ValAcc 0.7660\n",
            "Epoch 176 | Loss 0.7102 | TrainAcc 0.9786 | ValAcc 0.7660\n",
            "Epoch 177 | Loss 0.7061 | TrainAcc 0.9786 | ValAcc 0.7660\n",
            "Epoch 178 | Loss 0.7020 | TrainAcc 0.9786 | ValAcc 0.7660\n",
            "Epoch 179 | Loss 0.6980 | TrainAcc 0.9786 | ValAcc 0.7680\n",
            "Epoch 180 | Loss 0.6940 | TrainAcc 0.9786 | ValAcc 0.7700\n",
            "Epoch 181 | Loss 0.6901 | TrainAcc 0.9786 | ValAcc 0.7720\n",
            "Epoch 182 | Loss 0.6862 | TrainAcc 0.9786 | ValAcc 0.7720\n",
            "Epoch 183 | Loss 0.6823 | TrainAcc 0.9786 | ValAcc 0.7720\n",
            "Epoch 184 | Loss 0.6785 | TrainAcc 0.9786 | ValAcc 0.7740\n",
            "Epoch 185 | Loss 0.6747 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 186 | Loss 0.6710 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 187 | Loss 0.6673 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 188 | Loss 0.6636 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 189 | Loss 0.6600 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 190 | Loss 0.6564 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 191 | Loss 0.6528 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 192 | Loss 0.6493 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 193 | Loss 0.6458 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 194 | Loss 0.6423 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 195 | Loss 0.6389 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 196 | Loss 0.6355 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 197 | Loss 0.6322 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 198 | Loss 0.6288 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 199 | Loss 0.6255 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Epoch 200 | Loss 0.6223 | TrainAcc 0.9786 | ValAcc 0.7760\n",
            "Test Accuracy 0.7830\n"
          ]
        }
      ],
      "source": [
        "model = GCN(G.ndata['feat'].shape[1], hidden_dim=8, num_class=7)\n",
        "train_whole(G, model, 'cuda', 200)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
